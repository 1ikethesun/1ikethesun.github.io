---

title:  "강화학습 1. 준비(3)"
excerpt: "강화학습 요약 노트"

categories:
  - rl
tags:
  - [강화학습, TIL]

toc: true
toc_sticky: true

date: 2024-05-09
last_modified_at: 2024-05-09

---

# 1.3. 방책

## 1.3.1. 방책의 분류

__결정적 방책__(deterministic policy) $\pi_d : \mathcal{S} \rightarrow \mathcal{A}, \pi_d(s) = a$ 에 대해,

$$
\pi^d(a \mid s) \triangleq \begin{cases}1&(\text{if}\;a=\pi_d(s)), \\ 0&(\text{if etc}\;).  \end{cases}
$$

로 결정적 방책을 표현하면,  결정적 방책의 집합 

$$
\Pi^d \triangleq \{\pi^d : \mathcal{S} \times \mathcal{A} \rightarrow \{0,1\} \}
$$
은 정의로부터 확률적 방책 $\pi$의 집합 $\Pi$의 부분 집합임을 알 수 있다.

참고로 지시함수를 이용해, $\pi^d(a \mid s) \triangleq \mathbb{I}_{\\{a=\pi_d(s)\\}}$로 표현 가능하다.

($\mathbb{I}_{\\{A\\}} :$ 사상 A가 참이면 1, 거짓이면 0인 값을 갖는 함수)

__마르코프 방책__(Markov policy) : 확률적 방책 $\pi$나 결정적 방책 $\pi^d$와 같이, 과거의 경험과는 독립적으로 현재 상태 $s$에만 의존하여 행동을 선택하는 방책들의 糸열

__定常인 마르코프 방책__(stationary Markov policy) : 시간 $t$가 지나도, 변하지 않는 방책(의사결정 룰)로 이루어진 방책계열

$$
\boldsymbol{\pi}^s \triangleq {\{\pi\in\Pi,\pi\in\Pi,\dots\}}\in\boldsymbol{\Pi}^s\\
\boldsymbol{\pi}^{sd} \triangleq {\{\pi^d\in\Pi^d,\pi^d\in\Pi^d,\dots\}}\in\boldsymbol{\Pi}^{sd}
$$

(참고로 s가 붙은 이유는, 정상인 마르코프 정책이란 걸 표현한 것이다.)

__非定常인 마르코프 방책__ : 일반적인 마르코프 방책, 시간 $t$가 지날 때마다, 이에 따르는 방책함수가 변화한다.

$$
\boldsymbol{\pi}^m \triangleq {\{\pi_0 \in \Pi, \pi \in \Pi,\dots\}} \in \boldsymbol{\Pi}^M
$$


__非마르코프 방책__ : 현재 상태 $s$만이 아닌, 과거의 경험에도 의존해서 행동을 선택하는 방책.

즉, __이력__(history) $h \triangleq $ ${\\{s_0, a_0, r_0, \dots, s_{t-1}, a_{t-1}, r_{t-1}, s_t \\}} \in \mathcal{H}_t $ 에 대해서, __이력의존 방책__(history dependent policy) 

$\pi_t^h : \mathcal{A} \times \mathcal{H}_t \rightarrow [0,1], $

$\pi_t^h(a \mid h_t) \triangleq Pr(A=a \mid H_t=h_t)$ 

으로 정의할 수 있다.

(참고로 시간 $t$에 따른 이력의 확률변수, 그 실현값, 그 집합을 $H_t, h_t, \mathcal{H}_t$으로 썼으니 혼동하지 않도록 주의 요구)

이력의존 방책 $\pi_t^h$의 집합 $$
\Pi_t^h \triangleq \{\pi_t^h: \mathcal{A} \times \mathcal{H}_t \rightarrow [0, 1] : \sum\limits_{a \in \mathcal{A}} {\pi_t^h(a \mid h_t)} = 1\}
$$
로 표현하면,
$$
\boldsymbol{\pi}^h \triangleq {\{\pi_0^h\in\Pi_t^h,\pi_1^h\in\Pi_t^h,\dots\}}\in \boldsymbol{\Pi}^H \triangleq (\Pi_t^h)_{t\in \mathbb{N}_0}
$$
따라서 방책집합 $\Pi_t^h$는 "시간$t$가 될 때까지 얻을 수 있는 모든 정보를 조건"으로 하는 "모든 행동"에 관한 조건부 확률을 다 포함하기에, 시간$t$까지 생각할 수 있는 모든 방책을 포함한다. 다 종합해보면, 
$$
\boldsymbol{\Pi}^{SD}\subseteq \boldsymbol{\Pi}^{S}\subseteq \boldsymbol{\Pi}^{M}\subseteq\boldsymbol{\Pi}^{H} 
$$   

가 성립한다.

(이 외에도, "이력의존 결정적 방책계열", "비정상인 결정적 마르코프 결정 방책계열"등이 존재한다.)



## 1.3.2. 방책의 특징

이력의존 방책계열 집합 $\boldsymbol{\Pi}^H$에서 최선의 방책계열 $\boldsymbol{\pi}^h$를 고정할 수 있으면, 같은 정도의 효율이 나오는 다른 방책계열이 있을 순 있어도 더 좋은 방책계열은 존재하지 않는다.

즉, 방책계열 $\boldsymbol{\pi}$을 인수로 갖는 임의의 목적함수 $f$에 대해서,

$ \max\limits_{\boldsymbol{\pi}\in\boldsymbol{\Pi}^{SD}} f(\boldsymbol{\pi}) \leq \max\limits_{\boldsymbol{\pi}\in\boldsymbol{\Pi}^{S}} f(\boldsymbol{\pi}) \leq\max\limits_{\boldsymbol{\pi}\in\boldsymbol{\Pi}^{M}} f(\boldsymbol{\pi}) \leq\max\limits_{\boldsymbol{\pi}\in\boldsymbol{\Pi}^{H}} f(\boldsymbol{\pi})$

가 성립한다. 

(참고로, 목적함수 $f$는 마르코프 결정과정 $M$에 의존하므로, $f(\boldsymbol{\pi};M)$으로 써야하나, 너무 자명하므로 $M$을 생략한 것이다.)

최적의 방책을 구하려면,
$$
\underset{\boldsymbol{\pi} \in \boldsymbol{\Pi}^H}{\mathrm{argmax}} f(\boldsymbol{\pi})
$$
 라는 최적화 문제를 풀면 되지만, 방책 크기가 시간에 따라 폭발적으로 커지기에, 일반적인 $\boldsymbol{\Pi}^H$에 대한 최적화 문제를 다루는 건 매우 힘들다.

다루기 힘든 것을 대략적으로 파악하기 위해 몇몇의 방책 집합의 사이즈를 구해보자.

(1) 정상인 결정적 마르코프 방책의 집합 $\boldsymbol{\Pi}^{SD}$같은 경우, 집합 속 요소의 개수, 즉 방책계열의 개수는 원래의 결정적 방책을 계열로 늘여 놓은 것들의 개수이므로, 결정적 방책의 개수와 같다. 따라서

$\vert \boldsymbol{\Pi}^H \vert =  {\vert \Pi^d \vert} = {\vert \mathcal{A} \vert}^{\vert \mathcal{S} \vert}$

(2) $0~T$까지의 시간의 비정상인 결정적 마르코프 방책계열의 집합
$$
\boldsymbol{\Pi}_{0:T}^{MD} \triangleq \big\{\{\pi_0^d, \dots, \pi_T^d  \}:\pi_t^d \in \Pi^d, \, \forall t \in \{0, \dots, T\} \big\}
$$
라 할 수 있고, 이때 사이즈를 생각해보자. 어느 시간 $t$에 대해, 결정적 방책 집합 속 모든 방책이 가능하고, 이는 모든 시간 $0~T$에 관해 적용가능하므로, 
$$
\vert \boldsymbol{\Pi}_{0:T}^{MD}\vert = \prod\limits_{t=0}^T \vert \Pi^d \vert = (\vert \mathcal{A} \vert ^{\vert\mathcal{S}\vert})^{T+1}
$$
라고 구할 수 있다.

(3) $0~T$까지의 시간의 이력의존 결정적 방책의 집합
$$
\boldsymbol{\Pi}_{0:T}^{HD} \triangleq \big\{\{\pi_0^{h,d}, \dots, \pi_T^{h,d}  \}:\pi_t^{h,d} \in \Pi_t^{h,d}, \, \forall t \in \{0, \dots, T\} \big\}\\
\Pi_t^{h,d} \triangleq \{\pi^{h,d}: \mathcal{H}_t \rightarrow \mathcal{A}  \}
$$
여기서  $\mathcal{H}_t \ni h_t = \{s_0, a_0,r_0, \dots, s_{t-1},a_{t-1},r_{t-1},s_t \}$의 개수에 대해서 생각해보자. 이력의 요소를 잘 보면, 이력의 개수를 생각할 때, 일단 상태$s$의 개수, 행동$a$의 개수가 서로 곱해진다는 것은 직관적으로 알 수 있을 것이다. 이떄 보수 $r$의 개수는 이력의 개수의 영향을 주냐는 것인데, 보수의 정의를 생각해보면, 영향을 주지 않는다는 것을 알 수 있다. 보수란 상태와 행동이 정해질 때, 자연스럽게 정해지는 것이기에 이력의 개수에 영향을 주지 않는다. 따라서
$$
\vert \boldsymbol{\Pi}_{0:T}^{HD}\vert = \prod\limits_{t=0}^T \vert \Pi_t^{h,d} \vert = \prod\limits_{t=0}^T \vert \mathcal{A} \vert ^{\vert\mathcal{H}_t \vert} = \prod\limits_{t=0}^T \vert \mathcal{A} \vert ^{{\vert\mathcal{S}\vert}^{t+1} {\vert\mathcal{A}\vert}} 
$$
가 성립한다. 

결론적으로, (3)의 경우 시간이 지남에 따라 집합의 크기는 초지수함수적으로 커져, 다루기 힘들다는 것을 알 수 있다. 하지만, 다음으로 배울 명제로부터, 마르코프 방책만을 다루는 것으로도 많은 경우에 충분하다는 것을 알 수 있다.



### 명제1.1. 마르코프 방책의 타당성

$$
\forall M = \{ \mathcal{S}, \mathcal{A}, p_{s_0}, p_{T}, g \}, \forall \boldsymbol{\pi}^h = \{ \pi_0^h, \pi_1^h, \dots \} \in \boldsymbol{\Pi}^H,\\\
\exists \boldsymbol{\pi}^m = \{ \pi_0^m, \pi_1^m, \dots \} \in \boldsymbol{\Pi}^M s.t.\, 
\forall (t,s,a) \in \mathbb{N}_0 \times \mathcal{S} \times \mathcal{A}\\\
Pr(S_t=s, A_t=a \mid M(\boldsymbol{\pi}^h)) = Pr(S_t=s, A_t=a \mid M(\boldsymbol{\pi}^m))
$$



