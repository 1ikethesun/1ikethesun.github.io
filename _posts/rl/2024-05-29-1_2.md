---
title:  "강화학습을 읽고 ... 1. 준비(2)"
excerpt: "모리무라 선생님의 강화학습을 읽고 요약하기 위한 포스트입니다."

categories:
  - rl
tags:
  - [강화학습, TIL]

toc: true
toc_sticky: true
 
date: 2024-05-29
last_modified_at: 2024-05-29
---

# 1.2 마르코프 결정 과정과 순차적 의사 결정 문제

## 1.2.2. 마르코프 결정 과정

__확률제어과정__(stochastic cotrol process) : __상태__(state)만 다루는 확률과정이 아닌, 행동 등을 추가한 확률과정이다.

강화학습에선 행동 선택 룰의 최적화를 구해야하므로, 확률제어과정을 알아보도록 하자.

__마르코프 결정과정__(Markov decision process; MDP) : 마르코프 체인에, __행동__(action)과 어떤 상태에서 고른 행동에 따른 __보수__(reward)를 추가한 확률제어과정이다.

$M \triangleq {\\{S, A, p_{s_{0}}, p_{\mathsf{T}}, g\\}}$. 마르코프 결정과정 M의 요소는 다음과 같다.

$ \bullet $유한상태집합 $\mathcal{S} \triangleq {\\{1, \dots, \vert \mathcal{S} \vert \\}} \ni s$

$ \bullet $ 유한행동집합 $\mathcal{A} \triangleq {\\{a^1, \dots, a^{\vert \mathcal{A} \vert}\\}} \ni a $

$ \bullet $ 초기상태확률함수 $p_{s_{0}}: \mathcal{S} \rightarrow [0,1] , p_{s_{0}}(s) \triangleq Pr(S_{0}=s)$

$ \bullet $ 상태전이확률함수 $p_{\mathsf{T}}: \mathcal{S} \times  \mathcal{S} \times \mathcal{A}  \rightarrow [0,1], p_{ \mathsf{T}}(s' \mid s,a)  \triangleq Pr(S_{t+1} = s'  \mid S_t = s, A_t = a),  \forall t  \in  \mathbb{N}_0 $

$  \bullet $ 보수함수 $g :  \mathcal{S}  \times  \mathcal{A}  \rightarrow  \mathbb{R}$


