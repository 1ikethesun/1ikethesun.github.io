---

title:  "강화학습 1. 준비(3)"
excerpt: "강화학습 요약 노트"

categories:
  - rl
tags:
  - [강화학습, TIL]

toc: true
toc_sticky: true

date: 2024-05-09
last_modified_at: 2024-05-09

---

# 1.3. 방책

## 1.3.1. 방책의 분류

__결정적 방책__(deterministic policy) $\pi_d : \mathcal{S} \rightarrow \mathcal{A}, \pi_d(s) = a$ 에 대해,
$$
\pi^d(a \mid s) \triangleq \begin{cases}1&(\text{if}\;a=\pi_d(s)), \\ 0&(\text{if etc}\;).  \end{cases}
$$
로 결정적 방책을 표현하면,  결정적 방책의 집합 
$$
\Pi^d \triangleq \{\pi^d : \mathcal{S} \times \mathcal{A} \rightarrow \{0,1\} \}
$$
은 정의로부터 확률적 방책 $\pi$의 집합 $\Pi$의 부분 집합임을 알 수 있다.

참고로 지시함수를 이용해, $\pi^d \triangleq \mathbb{I}_{\\{a=\pi_d(s)\\}}$로 표현 가능하다.

($\mathbb{I}_{\\{A\\}} :$ 사상 A가 참이면 1, 거짓이면 0인 값을 갖는 함수)

__마르코프 방책__(Markov policy) : 확률적 방책 $\pi$나 결정적 방책 $\pi^d$와 같이, 과거의 경험과는 독립적으로 현재 상태 $s$에만 의존하여 행동을 선택하는 방책들의 糸열

__定常인 마르코프 방책__(stationary Markov policy) : 시간 $t$가 지나도, 변하지 않는 방책(의사결정 룰)로 이루어진 방책계열
$$
\boldsymbol{\pi}^s \triangleq {\{\pi\in\Pi,\pi\in\Pi,\dots\}}\in\boldsymbol{\Pi}^s\\
\boldsymbol{\pi}^{sd} \triangleq {\{\pi^d\in\Pi^d,\pi^d\in\Pi^d,\dots\}}\in\boldsymbol{\Pi}^{sd}
$$
(참고로 s가 붙은 이유는, 정상인 마르코프 정책이란 걸 표현한 것이다.)

__非定常인 마르코프 방책__ : 일반적인 마르코프 방책, 시간 $t$가 지날 때마다, 이에 따르는 방책함수가 변화한다.
$$
\boldsymbol{\pi}^m \triangleq {\{\pi_0 \in \Pi, \pi \in \Pi,\dots\}} \in \boldsymbol{\Pi}^M
$$
 

__非마르코프 방책__ : 현재 상태 $s$만이 아닌, 과거의 경험에도 의존해서 행동을 선택하는 방책.

즉, __이력__(history) $h \triangleq $ ${\\{s_0, a_0, r_0, \dots, s_{t-1}, a_{t-1}, r_{t-1}, s_t \\}} \in \mathcal{H}_t $ 에 대해서, __이력의존 방책__(history dependent policy) $\pi_t^h : \mathcal{A} \times \mathcal{H}_t \rightarrow [0,1], $

$\pi_t^h(a \mid h_t) \triangleq Pr(A=a \mid H_t=h_t)$ 

으로 정의할 수 있다.

(참고로 시간 $t$에 따른 이력의 확률변수, 그 실현값, 그 집합을 $H_t, h_t, \mathcal{H}_t$으로 썼으니 혼동하지 않도록 주의 요구)

이력의존 방책 $\pi_t^h$의 집합 $\Pi_t^h \triangleq {\big\{\pi_t^h : \mathcal{A}\times\mathcal{H}_t \rightarrow[0,1]:\sum\limits_{a\in\mathcal{A}} \pi_t^h(a \mid h_t) = 1  \big\}}$

로 표현하면,
$$
\boldsymbol{\pi}^h \triangleq {\{\pi_0^h\in\Pi_t^h,\pi_1^h\in\Pi_t^h,\dots\}}\in \boldsymbol{\Pi}^H \triangleq (\Pi_t^h)_{t\in \mathbb{N}_0}
$$
정의에 의하면 방책집합 $\Pi_t^h$는 "시간$t$가 될 때까지 얻을 수 있는 모든 정보를 조건"으로 하는 "모든 행동"에 관한 조건부 확률을 다 포함하기에, 시간$t$까지 생각할 수 있는 모든 방책을 포함한다. 다 종합해보면, 
$$
\boldsymbol{\Pi}^{SD}\subseteq \boldsymbol{\Pi}^{S}\subseteq \boldsymbol{\Pi}^{M}\subseteq\boldsymbol{\Pi}^{H} 
$$
가 성립한다.

(이 외에도, "이력의존 결정적 방책계열", "비정상인 결정적 마르코프 결정 방책계열"등이 존재한다.)



## 1.3.2. 방책의 특징

이력의존 방책계열 집합 $\boldsymbol{\Pi}^H$에서 최선의 방책계열 $\boldsymbol{\pi}^h$를 고정할 수 있으면, 같은 정도의 효율이 나오는 다른 방책계열이 있을 순 있어도 더 좋은 방책계열은 존재하지 않는다.

즉, 방책계열 $\boldsymbol{\pi}$을 인수로 갖는 임의의 목적함수 $f$에 대해서,

$ \max\limits_{\boldsymbol{\pi}\in\boldsymbol{\Pi}^{SD}} f(\boldsymbol{\pi}) \leq \max\limits_{\boldsymbol{\pi}\in\boldsymbol{\Pi}^{S}} f(\boldsymbol{\pi}) \leq\max\limits_{\boldsymbol{\pi}\in\boldsymbol{\Pi}^{M}} f(\boldsymbol{\pi}) \leq\max\limits_{\boldsymbol{\pi}\in\boldsymbol{\Pi}^{H}} f(\boldsymbol{\pi})$

가 성립한다. 

(참고로, 목적함수 $f$는 마르코프 결정과정 $M$에 의존하므로, $f(\boldsymbol{\pi};M)$으로 써야하나, 너무 자명하므로 $M$을 생략한 것이다.)

