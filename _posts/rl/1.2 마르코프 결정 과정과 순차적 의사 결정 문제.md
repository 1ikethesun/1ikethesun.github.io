평균 매출(평균 보수)를 최대로 하는 방책은 D이고, 세일을 남발하지 않고 고객의 구매 욕구가 high일 때 세일을 실시해야한다는 것을 알 수 있다. 한편 근시안적으로 즉시적으로 매출을 올리는 것은 방책 A이나, 근시안적으로는 최선의 선택일지라도 평균 매출이란 장기적 평가에서는 최악의 선택임을 알 수 있다. 이처럼 강화 학습은 당장은 손해가 있더라도 종합적으로 이익을 얻어내는 방책을 학습하는 것을 목적으로 두고 있다.



## 1.2 마르코프 결정 과정과 순차적 의사 결정 문제

### 1.2.1 확률 과정과 마르코프성

<span style="color: red">수학적 확률(probabilty)</span> : 같은 조건 속에서 여러 번 반복 가능한 동일한 시행에 의해 발생하는 각 사상의 가능성을 모두 정량적으로 표현한 것. 사상 $A$의 확률을 $Pr(A)$로 표기하고 이는 사상 $A$가 어떤 시행을 랜덤으로 했을 때 발생할 확률을 의미한다.



확률 변수(random variable) : 표본 공간의 각 원소에 하나의 실수를 대응시킬 때, 이 실수를 확률변수라 하며, 확률변수는 함수이다. 자세한건 확률과 통계에서

확률 변수를 대문자 $X$로, 그에 해당하는 실현값을 소문자 $x$로 구별하고, 확률 변수의 

얻어지는 값(실현값)의 집합을 $\chi$로 표현할 때, 주사위에 나올 수 있는 면을 확률 변수로 두면 확률은
$$
Pr(X=x) =\dfrac{1}{6}, \forall x \in \chi \triangleq \{1,2, \dots,6\}
$$
로 표현할 수 있다. 이처럼 확률 변수과 확률 간의 대응 관계를 __확률 분포__(probability distribution)혹은 간단히 __분포__라고 말한다.

다음으로 __확률 과정__(stochastic process)이란, 주사위를 한 번만 던지는 것이 아닌 여러 번 반복해 던져서 나오는 눈을 차례대로 나열한 수열, 혹은 눈의 누적합의 수열처럼 변수의 값이 시간과 함께 확률적으로 변화하는 확률 변수의 계열을 의미한다. 따라서 확률 과정은 시간 스텝 $t$를 파라미터로 하여,  ${X_t, t \in \tau}$ 라고 쓰는 경우가 많다.   $\tau$는 시간 스텝 $t$가 취할 수 있는 값의 집합으로, 연속 시간을 다룰 때에는 $\tau$ 대신에 실수 집합 $\mathbb{R}$ 로 하는 경우도 있으나, 이 곳에서는 이산적인 점열로 만들어지는 집합을 상정해서 서술하겠다.
$$
\{X_t, t \in \mathbb{N} \}\triangleq X_1, X_2, \dots (또는 \{X_t,t \in \mathbb{N_0}\}\triangleq X_0, X_1, \dots)
$$
일반적인 확률 과정에서는, 시간 스텝 $t$의 확률 변수 $X_t$가 $x \in \chi$를 취할 확률은,
$$
Pr(X_t=x|X_1=x_1, \dots,X_{t-1}=x_{t-1})
$$
처럼 시간 스텝 $t$ 이전의 모든 실현치의 의존한다. 여기서 $Pr(A|B)$는 조건부확률을 의미한다.

한편, 강한 제약이 걸린 더 단순한 확률 과정으로서, 각 확률 변수 $X_1, X_2, \dots$ 가 서로 독립이고 동일의 확률분포를 따르는 경우를 생각해보자. 이때, #X_1, X_2, \dots#는 __독립동일분포__(independent and identically distributed; i.i.d)를  따른다라고 하며, $ \forall x_1,x_2,\dots,x_{t-1},x \in \chi에 대해$
$$
Pr(X_t|X_1=x_1, X_2=x_2, \dots,X_{t-1}=x_{t-1})=Pr(X_k=x), \forall k \in \mathbb{N}
$$

가 성립한다. 즉 전에 무슨 사건이 벌어졌던 간에 영향을 받지 않고 어떠한 시간대에서도 실현치 $x$ 가 발생할 확률은 동일하다는 의미이다.

즉, 데이터가 i.i.d.를 따른다면 데이터의 순서, 시계열성을 고려하지 않고, 표준적인 패턴 인식이나 기계학습의 방법을 이용할 수 있기에 다루기 쉽다.

허나, 대다수의 많은 의사결정의 문제에 대해 i.i.d.의 가정을 두는 것은 불가능하기에, 강화학습에서는 i.i.d.보다 더 약한 제약인 __마르코프性__(Markov property)을 가정한다(i.i.d.와 마르코프성의 정의로부터 어느 확률과정이 i.i.d.를 따른다면, 마르코프性도 만족하지만 역은 성립하지 않는다.)

마르코프性이란, 미래의 확률변수의 조건부 확률분포가 현 시간 스텝 $t$의 값 $x_t$에만 의존해서 $x_t$가 주어진다면 $t-1$이전의 값 $x_1, x_2,\dots,x_{t-1}$에는 의존하지 않는 성질이다. 즉 마르코프性이라는 특징을 갖는 확률과정은, $\forall t,k \in \mathbb{N}, x_1,\dots,x_t,x \in \chi에 대해$
$$
Pr(X_{t+k}=x|X_1=x_1,\dots,X_t=x_t)=Pr(X_{t+k}=x|X_t=x_t)
$$
을 만족한다. 확률변수 $X$를 __상태변수__라고 보면, $Pr(X_{t+1}=x'|X_t=x)$는 상태 $x$로부터 다음 스텝에서 상태 $x'$에 전이하는 확률을 표현한 것이기에, 일반적으로 상태전이확률(state transition probability)라 한다. 또 마르코프性를 갖는 확률과정을 __마르코프과정__(Markov process)라 하며, 게다가 상태변수가 취할 수 있는 값이 이산적(유한 또는 가산)인 경우, __마르코프 체인__(Markov chain)이라 한다.

