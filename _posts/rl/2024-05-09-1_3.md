---

title:  "강화학습 1. 준비(3)"
excerpt: "강화학습 요약 노트"

categories:
  - rl
tags:
  - [강화학습, TIL]

toc: true
toc_sticky: true

date: 2024-05-09
last_modified_at: 2024-05-09

---

# 1.3. 방책

## 1.3.1. 방책의 분류

__결정적 방책__(deterministic policy) $\pi_d : \mathcal{S} \rightarrow \mathcal{A}, \pi_d(s) = a$ 에 대해,

$$
\pi^d(a \mid s) \triangleq \begin{cases}1&(\text{if}\;a=\pi_d(s)), \\ 0&(\text{if etc}\;).  \end{cases}
$$

로 결정적 방책을 표현하면,  결정적 방책의 집합 

$$
\Pi^d \triangleq \{\pi^d : \mathcal{S} \times \mathcal{A} \rightarrow \{0,1\} \}
$$

은 정의로부터 확률적 방책 $\pi$의 집합 $\Pi$의 부분 집합임을 알 수 있다.

참고로 지시함수를 이용해, $\pi^d(a \mid s) \triangleq \mathbb{I}_{\\{a=\pi_d(s)\\}}$로 표현 가능하다.

($\mathbb{I}_{\\{A\\}} :$ 사상 A가 참이면 1, 거짓이면 0인 값을 갖는 함수)

__마르코프 방책__(Markov policy) : 확률적 방책 $\pi$나 결정적 방책 $\pi^d$와 같이, 과거의 경험과는 독립적으로 현재 상태 $s$에만 의존하여 행동을 선택하는 방책들의 糸열

__定常인 마르코프 방책__(stationary Markov policy) : 시간 $t$가 지나도, 변하지 않는 방책(의사결정 룰)로 이루어진 방책계열

$$
\boldsymbol{\pi}^s \triangleq {\{\pi\in\Pi,\pi\in\Pi,\dots\}}\in\boldsymbol{\Pi}^s\\
\boldsymbol{\pi}^{sd} \triangleq {\{\pi^d\in\Pi^d,\pi^d\in\Pi^d,\dots\}}\in\boldsymbol{\Pi}^{sd}
$$

(참고로 s가 붙은 이유는, 정상인 마르코프 정책이란 걸 표현한 것이다.)

__非定常인 마르코프 방책__ : 일반적인 마르코프 방책, 시간 $t$가 지날 때마다, 이에 따르는 방책함수가 변화한다.

$$
\boldsymbol{\pi}^m \triangleq {\{\pi_0 \in \Pi, \pi \in \Pi,\dots\}} \in \boldsymbol{\Pi}^M
$$


__非마르코프 방책__ : 현재 상태 $s$만이 아닌, 과거의 경험에도 의존해서 행동을 선택하는 방책.

즉, __이력__(history) $h \triangleq $ ${\\{s_0, a_0, r_0, \dots, s_{t-1}, a_{t-1}, r_{t-1}, s_t \\}} \in \mathcal{H}_t $ 에 대해서, __이력의존 방책__(history dependent policy) 

$\pi_t^h : \mathcal{A} \times \mathcal{H}_t \rightarrow [0,1], $

$\pi_t^h(a \mid h_t) \triangleq Pr(A=a \mid H_t=h_t)$ 

으로 정의할 수 있다.

(참고로 시간 $t$에 따른 이력의 확률변수, 그 실현값, 그 집합을 $H_t, h_t, \mathcal{H}_t$으로 썼으니 혼동하지 않도록 주의 요구)

이력의존 방책 $\pi_t^h$의 집합 

$$
\Pi_t^h \triangleq \{\pi_t^h: \mathcal{A} \times \mathcal{H}_t \rightarrow [0, 1] : \sum\limits_{a \in \mathcal{A}} {\pi_t^h(a \mid h_t)} = 1\}
$$

로 표현하면,

$$
\boldsymbol{\pi}^h \triangleq {\{\pi_0^h\in\Pi_t^h,\pi_1^h\in\Pi_t^h,\dots\}}\in \boldsymbol{\Pi}^H \triangleq (\Pi_t^h)_{t\in \mathbb{N}_0}
$$

따라서 방책집합 $\Pi_t^h$는 "시간$t$가 될 때까지 얻을 수 있는 모든 정보를 조건"으로 하는 "모든 행동"에 관한 조건부 확률을 다 포함하기에, 시간$t$까지 생각할 수 있는 모든 방책을 포함한다. 다 종합해보면, 

$$
\boldsymbol{\Pi}^{SD}\subseteq \boldsymbol{\Pi}^{S}\subseteq \boldsymbol{\Pi}^{M}\subseteq\boldsymbol{\Pi}^{H} 
$$

가 성립한다.

(이 외에도, "이력의존 결정적 방책계열", "비정상인 결정적 마르코프 결정 방책계열"등이 존재한다.)



## 1.3.2. 방책의 특징

이력의존 방책계열 집합 $\boldsymbol{\Pi}^H$에서 최선의 방책계열 $\boldsymbol{\pi}^h$를 고정할 수 있으면, 같은 정도의 효율이 나오는 다른 방책계열이 있을 순 있어도 더 좋은 방책계열은 존재하지 않는다.

즉, 방책계열 $\boldsymbol{\pi}$을 인수로 갖는 임의의 목적함수 $f$에 대해서,

$$
\max\limits_{\boldsymbol{\pi}\in\boldsymbol{\Pi}^{SD}} f(\boldsymbol{\pi}) \leq \max\limits_{\boldsymbol{\pi}\in\boldsymbol{\Pi}^{S}} f(\boldsymbol{\pi}) \leq\max\limits_{\boldsymbol{\pi}\in\boldsymbol{\Pi}^{M}} f(\boldsymbol{\pi}) \leq\max\limits_{\boldsymbol{\pi}\in\boldsymbol{\Pi}^{H}} f(\boldsymbol{\pi})
$$

가 성립한다. 

(참고로, 목적함수 $f$는 마르코프 결정과정 $M$에 의존하므로, $f(\boldsymbol{\pi};M)$으로 써야하나, 너무 자명하므로 $M$을 생략한 것이다.)

최적의 방책을 구하려면,

$$
\underset{\boldsymbol{\pi} \in \boldsymbol{\Pi}^H}{\mathrm{argmax}} f(\boldsymbol{\pi})
$$

라는 최적화 문제를 풀면 되지만, 방책 크기가 시간에 따라 폭발적으로 커지기에, 일반적인 $\boldsymbol{\Pi}^H$에 대한 최적화 문제를 다루는 건 매우 힘들다.

다루기 힘든 것을 대략적으로 파악하기 위해 몇몇의 방책 집합의 사이즈를 구해보자.

(1) 정상인 결정적 마르코프 방책의 집합 $\boldsymbol{\Pi}^{SD}$같은 경우, 집합 속 요소의 개수, 즉 방책계열의 개수는 원래의 결정적 방책을 계열로 늘여 놓은 것들의 개수이므로, 결정적 방책의 개수와 같다. 따라서

$$
| \boldsymbol{\Pi}^{SD} | = | \Pi^d | = {| \mathcal{A} |}^{\vert\mathcal{S}\vert}
$$

(2) $0$~$T$까지의 시간의 비정상인 결정적 마르코프 방책계열의 집합

$$
 \boldsymbol{\Pi}_{0:T}^{MD} \triangleq \{ \{ \pi_0^d, \dots, \pi_T^d  \}:\pi_t^d \in \Pi^d, \, \forall t \in \{0, \dots, T \} \} 
$$

라 할 수 있고, 이때 사이즈를 생각해보자. 어느 시간 $t$에 대해, 결정적 방책 집합 속 모든 방책이 가능하고, 이는 모든 시간 $0~T$에 관해 적용가능하므로, 

$$
|\boldsymbol{\Pi}_{0:T}^{MD}| = \prod\limits_{t=0}^T |\Pi^d| = (  |\mathcal{A}|^{|\mathcal{S}|} )^{T+1}
$$

라고 구할 수 있다.

(3) $0$~$T$까지의 시간의 이력의존 결정적 방책의 집합

$$
\boldsymbol{\Pi}_{0:T}^{HD} \triangleq \{ \{ \pi_0^{h,d}, \dots, \pi_T^{h,d}  \}:\pi_t^{h,d} \in \Pi_t^{h,d}, \, \forall t \in \{0, \dots, T \} \}\\
\Pi_t^{h,d} \triangleq \{\pi^{h,d}: \mathcal{H}_t \rightarrow \mathcal{A}  \}
$$

여기서  $$ \mathcal{H}_t \ni h_t = \{s_0, a_0,r_0, \dots, s_{t-1},a_{t-1},r_{t-1},s_t \} $$의 개수에 대해서 생각해보자. 이력의 요소를 잘 보면, 이력의 개수를 생각할 때, 일단 상태$s$의 개수, 행동$a$의 개수가 서로 곱해진다는 것은 직관적으로 알 수 있을 것이다. 이떄 보수 $r$의 개수는 이력의 개수의 영향을 주냐는 것인데, 보수의 정의를 생각해보면, 영향을 주지 않는다는 것을 알 수 있다. 보수란 상태와 행동이 정해질 때, 자연스럽게 정해지는 것이기에 이력의 개수에 영향을 주지 않는다. 따라서

$$
\vert \boldsymbol{\Pi}_{0:T}^{HD}\vert = \prod\limits_{t=0}^T |\Pi_t^{h,d}| = \prod\limits_{t=0}^T {|\mathcal{A}|}^{|\mathcal{H}_t|} = \prod\limits_{t=0}^T |\mathcal{A}|^{|\mathcal{S}|^{t+1}|\mathcal{A}|^t}
$$

가 성립한다. 

결론적으로, (3)의 경우 시간이 지남에 따라 집합의 크기는 초지수함수적으로 커져, 다루기 힘들다는 것을 알 수 있다. 하지만, 다음으로 배울 명제로부터, 마르코프 방책만을 다루는 것으로도 많은 경우에 충분하다는 것을 알 수 있다.



### Prop 1.1. 마르코프 방책의 타당성

$$
\forall M = \{ \mathcal{S}, \mathcal{A}, p_{s_0}, p_{T}, g \}, \forall \boldsymbol{\pi}^h = \{ \pi_0^h, \pi_1^h, \dots \} \in \boldsymbol{\Pi}^H,\\
\exists \boldsymbol{\pi}^m = \{ \pi_0^m, \pi_1^m, \dots \} \in \boldsymbol{\Pi}^M s.t.\, \\
Pr(S_t=s, A_t=a \mid M(\boldsymbol{\pi}^h)) = Pr(S_t=s, A_t=a \mid M(\boldsymbol{\pi}^m))\\ 
\forall (t,s,a) \in \mathbb{N}_0 \times \mathcal{S} \times \mathcal{A}\\
$$

명제의 의의 : 어떤 이력의존의 비마르코프 방책에서 행동 선택을 했다고 하더라도, 각 시간 $t$ 에서의 $S_t$ 랑 $A_t$의 동시확률에 대해서는, 보다 간단한 방책인 마르코프 방책을 이용해도 정확하게 재현이 가능하다는 것을 보여준다. 또, 이 동시확률의 일치성을 달성하는 마르코프 방책의 구성 방법은 증명할 때 보도록 하자. 

주의해야할 건, 명제 1.1은 계열 전체$(S_0,A_0,\dots,S_t,A_t)$ 의 동시확률

$$
\begin{align} &Pr(S_0,A_0,\dots,S_t,A_t|M(\boldsymbol{\pi}^h)) \\
&= Pr(S_0,A_0,\dots,S_{t-1},A_{t-1},S_t,A_t|M({\boldsymbol{\pi}^m})) 
\end{align}
$$

의 일치성까지 보여주는 것이 아니라 어디까지나 $(S_t,A_t)$의 동시주변확률 

$$
Pr(S_t,A_t) = \sum_{s_0 \in \mathcal{S}} \sum_{a_0 \in \mathcal{A}} \cdots\sum_{s_{t-1}\in \mathcal{S}} \sum_{a_{t-1}\in \mathcal{A}} Pr(S_0=s_0,A_0=a_0,\dots,S_{t-1}=s_{t-1},A_{t-1}=a_{t-1},S_t,A_t)
$$

의 일치성에 관한 결과이다.

$\mathcal{Proof}$

이력의존의 방책계열 $\boldsymbol{\pi}^h$에 따르는 마르코프 결정과정 $M(\boldsymbol{\pi}^h)$에 대해서, 각 시간 $t \in mathbb{N}_0$에 도달할 확률이 $0$이 아닌 상태

$$
s\in \mathcal{S}_t \triangleq \{ s \in \mathcal{S}: Pr(S_t=s |M(\boldsymbol{\pi}^h))>0 \}
$$

에 대해서,

$$
{\pi^{m\star}_t}(a|s)\triangleq \frac{Pr(S_t=s,A_t=a|M(\boldsymbol{\pi}^h))}{Pr(S_t=s|M(\boldsymbol{\pi}^h))}, \, \forall a \in \mathcal{A}
$$

로 방책을 정의한 방책 계열 $\boldsymbol{\pi}^{m\star} \triangleq \\{ \pi^{m\star}_0,\pi^{m\star}_1,\dots \\} $  을 만들자. 이 마르코프 방책계열은 명제 1.1을 만족한다. 귀납법을 이용해 증명하면, 

$$
\begin{align} &\forall \boldsymbol{\pi}^h \in \boldsymbol{\Pi}^H, \forall \boldsymbol{\pi}^m \in \boldsymbol{\Pi}^M, \\
&Pr(S_0 = s |M(\boldsymbol{\pi}^h))\\
&=Pr(S_0=s|p_{s_0})=Pr(S_0=s|M(\boldsymbol{\pi}^m)), \, \forall s \in \mathcal{S}\\
\end{align}
$$

가 성립한다. 왜냐하면, $M =  \{ \mathcal{S}, \mathcal{A}, p_{s_0}, p_{T}, g \}$ 이고, $ M( \pi) =  \{ \mathcal{S}, \mathcal{A}, p_{s_0}, p_{T}, g ,\pi  \}$이므로, 이력의존 비마르코프 결정과정이든, 마르코프 결정과정이든, 초기 상태 $S_0$가 정해지는 것은 초기상태확률에 기반한다.

다음으로, 
$\sum_{s \in \mathcal{S}_0} Pr(S_0=s|M(\boldsymbol{\pi}^h))=1$
이므로, $t=0$일 때,

$$
\begin{align} &Pr(S_0=s,A_0=a|M(\boldsymbol{\pi}^h)) \\
&=\frac{Pr(S_0=s,A_0=a|M(\boldsymbol{\pi}^h))}{Pr(S_0=s|M(\boldsymbol{\pi}^h))}Pr(S_0=s|M(\boldsymbol{\pi}^{m\star}))\\
&= \pi_0^{m\star}(a|s)Pr(S_0=s|M(\boldsymbol{\pi}^{m\star}))\\
&=Pr(S_0=s,A_0=a|M(\boldsymbol{\pi}^{m\star})), \, \forall (s,a) \in \mathcal{S}_0 \times \mathcal{A}
\end{align}
$$

가 성립하기에, $t=0$일 때의 명제1.1 이 성립한다. 

("위의 모든 초기 상태의 확률의 합이 1이므로"를 쓴 이유는 모든 초기 상태에 대해서 위와 같은 변환이 가능하다는 것을 보여주기 위해 쓴 것이다.)

다음으로 어느 $k \in \mathbb{N}_0$에 대해 명제1.1이 성립한다고 가정하자. 이때,

$$
\begin{align}
&Pr(S_{k+1}=s'|M(\boldsymbol{\pi}^h))\\
&=\sum_{s\in\mathcal{S}}\sum_{a\in\mathcal{A}}Pr(S_k=s,A_k=a|M(\boldsymbol{\pi}^h))p_T(s'|s,a)\\
&=\sum_{s\in\mathcal{S}}\sum_{a\in\mathcal{A}}Pr(S_k=s,A_k=a|M(\boldsymbol{\pi}^{m\star}))p_T(s'|s,a)\\
&=Pr(S_{k+1}=s'|M(\boldsymbol{\pi}^{m\star})), \, \forall s' \in \mathcal{S}
\end{align}
$$

가 만족한다. 따라서, ${\pi_t}^{m\star}(a|s)$의 정의로부터,

$$
\begin{align}
&Pr(S_{k+1}=s, A_{k+1}=a|M(\boldsymbol{\pi}^h))\\
&={\pi^{m\star}_{k+1}}(a|s)Pr(S_{k+1}=s|M(\boldsymbol{\pi}^h))\\
&={\pi^{m\star}_{k+1}}(a|s)Pr(S_{k+1}=s|M(\boldsymbol{\pi}^{m\star}))\\
&=Pr(S_{k+1}=s,A_{k+1}=a|M(\boldsymbol{\pi}^{m\star})), \, \forall (s,a) \in \mathcal{S}_{k+1} \times \mathcal{A}
\end{align}
$$

로 쓸 수 있고,  여기서도 $t=k+1$에 대한 모든 상태의 확률의 합이 1이므로,즉 $\sum_{s\in\mathcal{S}_{k+1}} Pr(S_{k+1}=s|M(\boldsymbol{\pi}^h))=1$이므로,  $k+1$에 대해서도 명제 1.1이 성립한다. 이것으로 귀납법에 의한 명제 1.1의 증명이 끝났다.



